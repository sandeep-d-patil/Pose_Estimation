{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RP-Group6_Pytroch_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeeprockstar/Pose_Estimation/blob/master/RP_Group6_Pytroch_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9DzGJ_8nwTV",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch implementation - Single Density \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7If2mES3ZCW",
        "colab_type": "text"
      },
      "source": [
        "This google colab document contains the Pytorch implementation of the single density model proposed by Prokudin, S. All codeblocks have a short description of its main function is. For an elaborate explanation please have a look at our blogpost: https://sandeeprockstar.github.io/Pose_Estimation/\n",
        "\n",
        "Authors: \\\\\n",
        "Seger Tak 4975154 \\\\\n",
        "Sandeep Patil 4861213"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SQO-6wt2eEp",
        "colab_type": "text"
      },
      "source": [
        "#### Setting up the connection between the relevant folder in Google Drive and Google Colab\n",
        "Enter your own path if its named differently (most probably!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isLijlhUoLuI",
        "colab_type": "code",
        "outputId": "00d61c59-a319-4196-8f68-1bf134da2d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "######################### Setup the right directory #####################\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.chdir('/content/drive/My Drive/Deep Learning/deep_direct_stat-master')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk_PYXd13DHz",
        "colab_type": "text"
      },
      "source": [
        "#### Importing all required modules and datasets to run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMqtXyVo6Jrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################## Required modules ###########################\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "import torchvision\n",
        "import torchvision.transforms as TF\n",
        "from torchsummary import summary\n",
        "from scipy.stats import sem\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "\n",
        "# importing the datasets\n",
        "from datasets import pascal3d\n",
        "from datasets import caviar\n",
        "from datasets import towncentre\n",
        "\n",
        "# The support functions are usually imported from a seperate file; support_functions.py\n",
        "\n",
        "# from support_functions import pdf\n",
        "# from support_functions import cosine_loss_py, von_mises_neg_log_likelihood_py\n",
        "# from support_functions import von_mises_log_likelihood_py\n",
        "# from support_functions import rad2bit_py, deg2bit_py, deg2bit, rad2deg, bit2deg_py, deg2rad\n",
        "# from support_functions import maad_from_deg_py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t56I6c03IXt",
        "colab_type": "text"
      },
      "source": [
        "#### Running the support functions\n",
        "In order to make the overview as clear as possible all code has been put into one notebook, including the support functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKqECGk325IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################### LOSS FUNCTIONS ################################\n",
        "def cosine_loss_py(y_target, y_pred):\n",
        "    loss = 1 - torch.sum(torch.mul(y_target, y_pred), dim=1)\n",
        "    mean_loss = torch.mean(loss)\n",
        "    return mean_loss\n",
        "\n",
        "def von_mises_neg_log_likelihood_py(y_true, y_pred):\n",
        "    '''\n",
        "    :param y_true : array with ground truth angle in biternion representation (cos, sin) of shape [n_samples, 1]\n",
        "    :param y_pred : array with predicted mean angle (cos, sin) and kappa of shape [n_samples, 3]\n",
        "    :return: mean negative log likelihood\n",
        "    '''\n",
        "    mu_pred = y_pred[:, 0:2]\n",
        "    kappa_pred = y_pred[:, 2:]\n",
        "    return -torch.mean(von_mises_log_likelihood_py(y_true, mu_pred, kappa_pred, input_type='biternion'))\n",
        "\n",
        "# Conversion of von_mises_log_likelihood_tf\n",
        "def von_mises_log_likelihood_py(y_true, mu_pred, kappa_pred, input_type='biternion'):\n",
        "    '''\n",
        "    Compute log-likelihood given data samples and predicted Von-Mises model parameters\n",
        "    :param y_true: true values of an angle in biternion (cos, sin) representation\n",
        "    :param mu_pred: predicted mean values of an angle in biternion (cos, sin) representation\n",
        "    :param kappa_pred: predicted kappa (inverse variance) values of an angle in biternion (cos, sin) representation\n",
        "    :param radian_input:\n",
        "    :return:\n",
        "    log_likelihood\n",
        "    '''\n",
        "    if input_type == 'degree':\n",
        "        scaler = 0.0174533\n",
        "        cosin_dist = torch.cos(scaler * (y_true - mu_pred))\n",
        "    elif input_type == 'radian':\n",
        "        cosin_dist = torch.cos(y_true - mu_pred)\n",
        "    elif input_type == 'biternion':\n",
        "        cosin_dist = torch.reshape(torch.sum(torch.mul(y_true, mu_pred), axis=1), [-1, 1])\n",
        "    log_likelihood = kappa_pred.to(device) * cosin_dist - \\\n",
        "                     torch.log(2 * torch.tensor([math.pi]).to(device)) - log_bessel_approx_py(kappa_pred.to(device)) #torch.log(2 * torch.tensor([math.pi])) - log_bessel_approx_py(kappa_pred) \n",
        "    return torch.reshape(log_likelihood, [-1, 1])\n",
        "\n",
        "# Conversion of log_bess_approx_tf\n",
        "def log_bessel_approx_py(x):\n",
        "    x = torch.reshape(x, [-1, 1])\n",
        "\n",
        "    def _log_bessel_approx_0(x):\n",
        "        bessel_taylor_coefs = torch.tensor([1.00000000e+00, 2.50000000e-01, 1.56250000e-02,\n",
        "                                          4.34027778e-04, 6.78168403e-06]).to(device)\n",
        "        m = bessel_taylor_coefs.shape[0]\n",
        "        deg = torch.reshape(torch.arange(0, m, 1)*2, [1, -1])\n",
        "        n_rows = x.size(0)\n",
        "        x_tiled = x.repeat(1,m)\n",
        "        deg_tiled = deg.repeat(n_rows,1)\n",
        "        deg_reshape = torch.reshape(bessel_taylor_coefs[0:m],[1,m])\n",
        "        coef_tiled = deg_reshape.repeat(n_rows,1)\n",
        "        deg_tiled = deg_tiled.type(torch.FloatTensor).to(device)\n",
        "        val = torch.log(torch.sum(torch.pow(x_tiled, deg_tiled)*coef_tiled, axis=1))\n",
        "        return torch.reshape(val, [-1, 1])\n",
        "\n",
        "    def _log_bessel_approx_large(x):\n",
        "        return x - 0.5*torch.log(2*torch.tensor([math.pi]).to(device)*x)          \n",
        "\n",
        "    res = torch.where(x > 5.0, _log_bessel_approx_large(x), _log_bessel_approx_0(x))\n",
        "\n",
        "    return res\n",
        "\n",
        "##################### ANGLE CONVERSION ################################\n",
        "\n",
        "def rad2bit_py(angles_rad):\n",
        "    \"\"\" radians to biternion ([cos, sin])\n",
        "    \"\"\"\n",
        "    return torch.tensor([torch.cos(angles_rad), torch.sin(angles_rad)]).to(device).T \n",
        "\n",
        "def deg2bit(angles_deg):\n",
        "    \"\"\" degrees to biternion ([cos, sin])\n",
        "    \"\"\"\n",
        "    angles_rad = np.deg2rad(angles_deg)\n",
        "    return np.array([np.cos(angles_rad), np.sin(angles_rad)]).T\n",
        "\n",
        "def deg2bit_py(angles_deg):\n",
        "    \"\"\" degrees to biternion ([cos, sin])\n",
        "    \"\"\"\n",
        "    angles_rad = angles_deg * torch.tensor([math.pi]).to(device) / 180              \n",
        "    print(angles_rad.shape)\n",
        "    print(torch.cos(angles_rad).shape)\n",
        "    print(torch.tensor([torch.cos(angles_rad),torch.sin(angles_rad)]).shape)\n",
        "    return torch.tensor([torch.cos(angles_rad),torch.sin(angles_rad)]).to(device).T \n",
        "\n",
        "def rad2deg(angle_rad):\n",
        "    return angle_rad * 180 / torch.tensor([math.pi]).to(device)\n",
        "\n",
        "def bit2deg_py(angles_bit):\n",
        "    \"\"\" biternion ([cos, sin]) ->  degrees\n",
        "    \"\"\"\n",
        "    return (rad2deg(torch.atan2(angles_bit[:,1], angles_bit[:,0])) + 360) %360\n",
        "\n",
        "def deg2rad(angle_deg):\n",
        "    return angle_deg * torch.tensor([math.pi]).to(device) / 180 \n",
        "\n",
        "def maad_from_deg_py(y_pred, y_target):\n",
        "    return  rad2deg(torch.abs(torch.atan2(torch.sin(deg2rad(y_target - y_pred)).to(device),\n",
        "                                          torch.cos(deg2rad(y_target - y_pred)).to(device)).to(device)).to(device)) \n",
        "    \n",
        "\n",
        "######################## PDF Function ####################################\n",
        "def pdf(model, x, x_vals):\n",
        "    n_images = x.shape[0]\n",
        "    x_vals_tiled = torch.ones(n_images).to(device)\n",
        "    preds = model(x)\n",
        "    mu_preds_bit = preds[:, 0:2]\n",
        "    if predict_kappa:\n",
        "        kappa_preds = preds[:,2:]\n",
        "    else:\n",
        "        kappa_preds = torch.ones([x.shape[0], 1]).to(device) * fixed_kappa_value\n",
        "    log_likelihoods = torch.zeros([n_images, len(x_vals)])\n",
        "    for xid, xval in enumerate(x_vals):\n",
        "        x_bit = rad2bit(x_vals_tiled * xval)\n",
        "        log_likelihoods[:,xid] = torch.exp(torch.squeeze(von_mises_log_likelihood_np(x_bit, mu_preds_bit, kappa_preds)))\n",
        "    return log_likelihoods"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQhKfCAL3V5P",
        "colab_type": "text"
      },
      "source": [
        "### loading and preparing all datasets\n",
        "PASCAL3D+, CAVIAR-o and TownCentre are loaded. The images are reshaped in order to prepare them for input in the Pytorch CNN. Also, the angles are converted into their biternion representation for the TownCentre and CAVIAR-o set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgl96FcHJTjR",
        "colab_type": "code",
        "outputId": "23db33c2-b61d-4750-f3b7-d12b036fef9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}      \n",
        "\n",
        "# Loading and preparing the PASCAL3D+ dataset\n",
        "cls = 'aeroplane' # if cls is None, all classes will be loaded\n",
        "pascaldb_path = 'data/pascal3d+_imagenet_train_test.h5'\n",
        "x_train_tf, y_train_tf, x_val_tf, y_val_tf, x_test_tf, y_test_tf = pascal3d.load_pascal_data(pascaldb_path, cls=cls)\n",
        "\n",
        "x_train = (torch.tensor(x_train_tf[:])).permute(0, 3, 1, 2).float()\n",
        "y_train = torch.tensor(y_train_tf[:])\n",
        "x_val = (torch.tensor(x_val_tf[:])).permute(0, 3, 1, 2).float() \n",
        "y_val = torch.tensor(y_val_tf[:])\n",
        "x_test = (torch.tensor(x_test_tf[:])).permute(0, 3, 1, 2).float() \n",
        "y_test = torch.tensor(y_test_tf[:])\n",
        "\n",
        "# Loading and preparing the CAVIAR-o dataset\n",
        "caviar_path = 'data/CAVIAR-o.pkl.gz'\n",
        "(xtr_cav, ytr_cav_deg, info_tr), (xval_cav, yval_cav_deg, info_val), (xte_cav, yte_cav_deg, info_te) = caviar.load_caviar(caviar_path)\n",
        "\n",
        "ytr_cav_bit = deg2bit(ytr_cav_deg)\n",
        "yval_cav_bit = deg2bit(yval_cav_deg)\n",
        "yte_cav_bit = deg2bit(yte_cav_deg)\n",
        "xtr_cav = (torch.tensor(xtr_cav[:])).permute(0, 3, 1, 2).float() \n",
        "ytr_cav_bit = torch.tensor(ytr_cav_bit[:])\n",
        "xval_cav = (torch.tensor(xval_cav[:])).permute(0, 3, 1, 2).float() \n",
        "yval_cav_bit = torch.tensor(yval_cav_bit[:])\n",
        "xte_cav = (torch.tensor(xte_cav[:])).permute(0, 3, 1, 2).float() \n",
        "yte_cav_bit = torch.tensor(yte_cav_bit[:])\n",
        "\n",
        "# Loading and preparing the TownCentre dataset\n",
        "towncentre_path = 'data/TownCentre.pkl.gz'\n",
        "(xtr_tc, ytr_tc_deg, img_names_tr), (xval_tc, yval_tc_deg, img_names_val), (xte_tc, yte_tc_deg, img_names_te) = towncentre.load_towncentre(towncentre_path)\n",
        "\n",
        "ytr_tc_bit = deg2bit(ytr_tc_deg)\n",
        "yval_tc_bit = deg2bit(yval_tc_deg)\n",
        "yte_tc_bit = deg2bit(yte_tc_deg)\n",
        "xtr_tc = (torch.tensor(xtr_tc[:])).permute(0, 3, 1, 2).float() \n",
        "ytr_tc_bit = torch.tensor(ytr_tc_bit[:])\n",
        "xval_tc = (torch.tensor(xval_tc[:])).permute(0, 3, 1, 2).float() \n",
        "yval_tc_bit = torch.tensor(yval_tc_bit[:])\n",
        "xte_tc = (torch.tensor(xte_tc[:])).permute(0, 3, 1, 2).float() \n",
        "yte_tc_bit = torch.tensor(yte_tc_bit[:])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train samples: 6916\n",
            "Number of validation samples: 874\n",
            "Number of test samples: 904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjOYMqKb4c_f",
        "colab_type": "text"
      },
      "source": [
        "### Loading the selected dataset into the dataloader\n",
        "This block is used to select a dataset and loading the data into the dataloader. This allows the images to be fed into the CNN batch-wise as well as shuffling the images during training. Set the following settings manually in this code block: shuffle, dataset selection and batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFiv3Kd8ZRuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class dataloader(Dataset):\n",
        "  def __init__(self, samples, labels):\n",
        "    self.labels = labels\n",
        "    self.samples = samples\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.samples)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    sample = self.samples[index]\n",
        "    label = self.labels[index]\n",
        "    return sample, label\n",
        "\n",
        "# Select dataset for analysis\n",
        "load_dataset = 'towncentre'\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}       \n",
        "\n",
        "if load_dataset == 'pascal':\n",
        "    train_set = dataloader(x_train, y_train[:, 0:2])\n",
        "    val_set = dataloader(x_val, y_val[:, 0:2])\n",
        "    test_set = dataloader(x_test, y_test[:, 0:2])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=100, shuffle=True, **kwargs)\n",
        "    val_loader = DataLoader(val_set, batch_size=15, **kwargs) # Add batch size in order to not load the entire set into the memory\n",
        "    test_loader = DataLoader(test_set, batch_size=15, **kwargs)\n",
        "\n",
        "elif load_dataset == 'caviar':\n",
        "    train_set = dataloader(xtr_cav, ytr_cav_bit[:, 0:2])\n",
        "    val_set = dataloader(xval_cav, yval_cav_bit[:, 0:2])\n",
        "    test_set = dataloader(xte_cav, yte_cav_bit[:, 0:2])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=100, shuffle=True, **kwargs)\n",
        "    val_loader = DataLoader(val_set, batch_size=15, **kwargs) # Add batch size in order to not load the entire set into the memory\n",
        "    test_loader = DataLoader(test_set, batch_size=15, **kwargs)\n",
        "\n",
        "elif load_dataset == 'towncentre':\n",
        "    train_set = dataloader(xtr_tc, ytr_tc_bit[:, 0:2])\n",
        "    val_set = dataloader(xval_tc, yval_tc_bit[:, 0:2])\n",
        "    test_set = dataloader(xte_tc, yte_tc_bit[:, 0:2])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=25, shuffle=True, **kwargs)\n",
        "    val_loader = DataLoader(val_set, batch_size=15, **kwargs) # Add batch size in order to not load the entire set into the memory\n",
        "    test_loader = DataLoader(test_set, batch_size=15, **kwargs)     \n",
        "\n",
        "data_loaders = {'train': train_loader, 'val': val_loader, 'test': test_loader} # setup a dataloader for the training & validation set\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csGThhujBHpg",
        "colab_type": "text"
      },
      "source": [
        "#### The deep neural network main class. \n",
        "Includes the VGG-style architecture, loss function selection, finetune kappa module, training and evaluation. The plot_pdf function has been transformed to Pytorch as well, but it has not been used due to time constraints.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYwG8hghxG8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class vgg_model_complete(nn.Module):\n",
        "    def __init__(self, predict_kappa=True, final_layer=False, l2_normalize_final=False,\n",
        "                 n_outputs=1, conv_dropout_val=0.2, fc_dropout_val=0.5, fc_layer_size=512):\n",
        "\n",
        "        self.predict_kappa = predict_kappa\n",
        "        self.final_layer = final_layer\n",
        "        self.l2_normalize_final = l2_normalize_final\n",
        "\n",
        "        super(vgg_model_complete, self).__init__()\n",
        "        self.VGG_backbone = nn.Sequential(\n",
        "            nn.Conv2d(3, 24, kernel_size=3, stride=1), \n",
        "            nn.BatchNorm2d(24),         \n",
        "            nn.ReLU(),               \n",
        "            nn.Conv2d(24, 24, kernel_size=3, stride=1), \n",
        "            nn.BatchNorm2d(24), \n",
        "            nn.MaxPool2d(2),            \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(24, 48, kernel_size=3, stride=1),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(48, 48, kernel_size=3, stride=1),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(48, 64, kernel_size=3, stride=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(conv_dropout_val), \n",
        "            nn.Flatten(),\n",
        "            nn.Linear(5*5*64, 512),  #5*5*64 for CAVIAR/TC, 49*49*64 for PASCAL \n",
        "            nn.ReLU(),                                                         \n",
        "            nn.Dropout2d(fc_dropout_val))                                       \n",
        "        self.fc1 = nn.Linear(512, n_outputs)\n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "        self.fc3 = nn.Linear(512, 2)\n",
        "\n",
        "    def forward(self, input): \n",
        "\n",
        "        x_vgg = self.VGG_backbone(input)\n",
        "\n",
        "        if self.final_layer:\n",
        "            x = self.fc1(x_vgg)\n",
        "            if self.l2_normalize_final:\n",
        "                x = F.normalize(x,dim=1,p=2)\n",
        "\n",
        "        if not self.final_layer:\n",
        "            if self.predict_kappa:\n",
        "                x_ypred = F.normalize(self.fc3(x_vgg), dim=1, p=2)\n",
        "                x_kappa = torch.abs(self.fc2(x_vgg))\n",
        "                x = torch.cat((x_ypred, x_kappa), 1)\n",
        "\n",
        "            if not self.predict_kappa:\n",
        "                x = F.normalize(self.fc3(x_vgg), dim=1, p=2)\n",
        "\n",
        "        return x\n",
        "\n",
        "class BiternionVGG:\n",
        "    def __init__(self, predict_kappa=True, loss_type='vm_likelihood', \n",
        "               fixed_kappa_value=1.0, **kwargs):\n",
        "          \n",
        "        self.predict_kappa = predict_kappa      \n",
        "        self.fixed_kappa_value = fixed_kappa_value \n",
        "        self.hyp_params = kwargs            \n",
        "        self.learning_rate = kwargs.get('learning_rate', 1.0e-3) \n",
        "        self.beta1 = kwargs.get('beta1', 0.9) \n",
        "        self.beta2 = kwargs.get('beta2', 0.999) \n",
        "        self.epsilon = kwargs.get('epsilon', 1.0e-7)\n",
        "        self.conv_dropout = kwargs.get('conv_dropout', 0.2) \n",
        "        self.fc_dropout = kwargs.get('fc_dropout', 0.5) \n",
        "        self.vgg_fc_layer_size = kwargs.get('vgg_fc_layer_size', 512) \n",
        "        self.loss_type = loss_type\n",
        "        self.loss = self._pick_loss()  \n",
        "            \n",
        "        self.model = vgg_model_complete(n_outputs=1, predict_kappa=self.predict_kappa, \n",
        "                                            final_layer=False, l2_normalize_final=False, \n",
        "                                            conv_dropout_val=self.conv_dropout, \n",
        "                                            fc_dropout_val=self.fc_dropout, \n",
        "                                            fc_layer_size=self.vgg_fc_layer_size)\n",
        "        self.model = self.model.to(device)\n",
        "        # summary(self.model, (3,50,50))   \n",
        "        \n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, \n",
        "                                betas=(self.beta1, self.beta2), eps=self.epsilon)\n",
        "      \n",
        "    def _pick_loss(self):\n",
        "        if self.loss_type == 'cosine':\n",
        "            print('using cosine loss')\n",
        "            self.loss = cosine_loss_py\n",
        "\n",
        "        elif self.loss_type == 'vm_likelihood':\n",
        "            print('using von Mises log likelihood loss')\n",
        "\n",
        "            if self.predict_kappa:\n",
        "                self.loss = von_mises_neg_log_likelihood_py\n",
        "\n",
        "            elif not self.predict_kappa:\n",
        "                def _von_mises_neg_log_likelihood_fixed_py(y_true, y_pred):\n",
        "                    mu_pred = y_pred[:, 0:2]\n",
        "                    kappa_pred = torch.ones([y_pred.shape[0], 1]).to(device) * self.fixed_kappa_value\n",
        "                    return -torch.mean(von_mises_log_likelihood_py(y_true, mu_pred, kappa_pred))\n",
        "                self.loss = _von_mises_neg_log_likelihood_fixed_py\n",
        "\n",
        "        return self.loss\n",
        "\n",
        "    def train(self, data_loaders, n_epochs): \n",
        "        since = time.time()                         \n",
        "\n",
        "        best_model_weights = copy.deepcopy(self.model.state_dict())\n",
        "        best_loss = 99999\n",
        "        loss_train = []\n",
        "        loss_val = []\n",
        "        for epoch in range(n_epochs):\n",
        "            print('Epoch {}/{}'.format(epoch, n_epochs - 1))\n",
        "            print('-' * 10)\n",
        "\n",
        "            # switch between training & validation phase of epoch\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    self.model.train()     # Set model to training mode\n",
        "                else:\n",
        "                    self.model.eval()      # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0    # initialize running loss for each epoch\n",
        "\n",
        "                # Iterate over data.\n",
        "                for i, data in enumerate(data_loaders[phase]): # iterate over data using predefined batch size\n",
        "                    x_input, y_true = data  # extract the input and labels from the data corresponding to the phase\n",
        "                    x_input, y_true = x_input.to(device), y_true.to(device) # Transfer data proccessing tasks to the GPU\n",
        "                    self.optimizer.zero_grad() # zero the parameter gradients\n",
        "                \n",
        "                    # forwardpass\n",
        "                    with torch.set_grad_enabled(phase == 'train'): # tracking history; only during the training phase\n",
        "                        y_pred = self.model(x_input) \n",
        "                        loss_batch = self.loss(y_true, y_pred)\n",
        "\n",
        "                        # backprop + optimization; only during the training phase\n",
        "                        if phase == 'train':\n",
        "                            loss_batch.backward(torch.ones_like(loss_batch))\n",
        "                            self.optimizer.step()\n",
        "                        \n",
        "                    # statistics \n",
        "                    running_loss += loss_batch.item() * len(x_input) \n",
        "                          \n",
        "                if phase == 'train':\n",
        "                    epoch_loss = running_loss / len(data_loaders['train'].dataset)\n",
        "                    loss_train.append(epoch_loss)\n",
        "                elif phase == 'val':\n",
        "                    epoch_loss = running_loss / len(data_loaders['val'].dataset)\n",
        "                    loss_val.append(epoch_loss)\n",
        "\n",
        "                print('{} Loss: {:.4f}'.format(\n",
        "                    phase, epoch_loss))\n",
        "\n",
        "                # deep copy the model scoring best on validation loss\n",
        "                if phase == 'val' and epoch_loss < best_loss:\n",
        "                    best_loss = epoch_loss\n",
        "                    best_model_weights = copy.deepcopy(self.model.state_dict())\n",
        "\n",
        "                    torch.save({'epoch': epoch,\n",
        "                    'model_state_dict': self.model.state_dict(),\n",
        "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                    'loss': loss_batch}, 'training_data/model_weights_caviar.tar')\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "            time_elapsed // 60, time_elapsed % 60))\n",
        "        print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "        # load best model weights\n",
        "        self.model.load_state_dict(best_model_weights)\n",
        "\n",
        "        if not self.predict_kappa:\n",
        "            self.finetune_kappa(data_loaders)\n",
        "\n",
        "        # plot and save losses\n",
        "        plt.plot(loss_train)\n",
        "        plt.plot(loss_val)\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('loss')\n",
        "        plt.legend(['training loss', 'validation loss'])\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "        np.savetxt('training_data/loss_train_PA_lr0-001_batch-50.csv', loss_train)\n",
        "        np.savetxt('training_data/loss_val_PA_lr0-001_batch-50.csv', loss_val)\n",
        "        return self.model\n",
        "\n",
        "    def finetune_kappa(self, data_loaders, max_kappa = 1000.0, verbose=False):\n",
        "        ytr_preds_bit = torch.Tensor().to(device)\n",
        "        with torch.no_grad():\n",
        "            for data in data_loaders['val']:\n",
        "                x, y_bit_batch = data\n",
        "                x = x.to(device)\n",
        "                y_preds_batch = self.model(x)[:,0:2]\n",
        "                ytr_preds_bit = torch.cat((ytr_preds_bit, y_preds_batch), 0)\n",
        "        y_bit = (data_loaders['val'].dataset.labels).to(device)\n",
        "        kappa_vals = torch.arange(0, max_kappa, 1.0).to(device)\n",
        "        log_likelihoods = torch.zeros(kappa_vals.shape).to(device)\n",
        "        print(y_bit.shape)\n",
        "        print(ytr_preds_bit.shape)\n",
        "        for i,kappa_val in enumerate(kappa_vals):\n",
        "            kappa_preds = torch.ones([y_bit.shape[0], 1]).to(device) * kappa_val\n",
        "            log_likelihoods[i] = torch.mean(von_mises_log_likelihood_py(y_bit, ytr_preds_bit,kappa_preds))\n",
        "            if verbose:\n",
        "                print(\"kappa: %f, log-likelihood: %f\" % (kappa_val,log_likelihoods[i]))\n",
        "        max_ix = torch.argmax(log_likelihoods)\n",
        "        self.fixed_kappa_value = kappa_vals[max_ix]\n",
        "        if verbose:\n",
        "            print(\"best kappa : %f\" % self.fixed_kappa_value)\n",
        "        return self.fixed_kappa_value\n",
        "\n",
        "    def evaluation(self, data_loaders, return_per_image=False): # removed the data_part!\n",
        "        kappa_preds = torch.Tensor().to(device)   # initialize empty tensors for concatenation\n",
        "        loss = torch.Tensor().to(device)         \n",
        "        ypreds = torch.Tensor().to(device) \n",
        "        with torch.no_grad():\n",
        "            for data in data_loaders['test']:\n",
        "                x, ytrue_bit_batch = data\n",
        "                x, ytrue_bit_batch = x.to(device), ytrue_bit_batch.to(device)\n",
        "                ypreds_batch = self.model(x)\n",
        "                ypreds = torch.cat((ypreds, ypreds_batch), 0)\n",
        "            ytrue_bit = (data_loaders['test'].dataset.labels).cuda()\n",
        "            ytrue_deg = bit2deg_py(ytrue_bit)\n",
        "            ypreds_deg = bit2deg_py(ypreds)   \n",
        "\n",
        "            if self.predict_kappa:\n",
        "                kappa_preds = ypreds[:, 2:]\n",
        "            \n",
        "            elif not self.predict_kappa:\n",
        "                kappa_preds = torch.ones([ytrue_deg.shape[0], 1]) * self.fixed_kappa_value\n",
        "\n",
        "            loss = (maad_from_deg_py(ypreds_deg, ytrue_deg).float()).cpu()\n",
        "\n",
        "        results = dict()\n",
        "        results['maad_loss'] = float(torch.mean(loss))\n",
        "        results['maad_loss_sem'] = float(sem(loss))\n",
        "        print(\"MAAD error : %f pm %fSEM\" % (results['maad_loss'],\n",
        "                                            results['maad_loss_sem']))\n",
        "    \n",
        "        results['mean_kappa'] = float(torch.mean(kappa_preds))\n",
        "        results['std_kappa'] = float(torch.std(kappa_preds,unbiased=False))\n",
        "\n",
        "        log_likelihoods = (von_mises_log_likelihood_py(ytrue_bit[:,0:2], ypreds[:,0:2], kappa_preds)).cpu()\n",
        "\n",
        "        results['log_likelihood_mean'] = float(torch.mean(log_likelihoods))\n",
        "        results['log_likelihood_sem'] = float(sem(log_likelihoods, axis=None)) \n",
        "        print(\"log-likelihood : %f pm %fSEM\" % (results['log_likelihood_mean'], \n",
        "                                                results['log_likelihood_sem']))\n",
        "\n",
        "        if return_per_image:                          # return_per_image=true --> update results dictionary\n",
        "            results['point_preds'] = bit2deg_py(deg2bit_py(ypreds_deg))\n",
        "            results['maad'] = loss\n",
        "            results['log_likelihood'] = log_likelihoods\n",
        "    \n",
        "        return results\n",
        "\n",
        "    def plot_pdf(data_loaders, step=1.0e-2,fid = 8):\n",
        "        \"\"\"fid is image number\n",
        "        \"\"\"\n",
        "\n",
        "        xval = np.arange(0, 2*np.pi, step) # prediction for angles between 0 and 360 degrees\n",
        "        x_pdf = pdf(x_test, xval) # calculation of probability distribution\n",
        "        angle = self.model(x_test) # predicting the value of angle\n",
        "        print(angle[1,0:2])\n",
        "\n",
        "        plt.axvline(np.deg2rad(y_test)[fid], c='orange', label='ground truth') # plot of ground truth value in radians\n",
        "        plt.axvline(angles.bit2rad(np.expand_dims(angle[1,0:2],axis=0)), c='darkblue', label='prediction') # plot of predicted value in radians\n",
        "        plt.plot(xval, x_pdf[fid], label='predicted density') #plot of probability function\n",
        "        plt.legend()\n",
        "        \n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrZxS7Gg4mID",
        "colab_type": "text"
      },
      "source": [
        "### Running the model\n",
        "The model can be run from this code bock. Select the following parameters: Predict kappa, number of epochs and loss type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfXD1e4975Ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.cuda.empty_cache()\n",
        "# # Initialize the model. Select predict_kappa and loss_type\n",
        "testing_model = BiternionVGG(predict_kappa=False, loss_type='vm_likelihood')\n",
        "\n",
        "# Testing and validation of the model\n",
        "testing_model.train(data_loaders, n_epochs = 70)\n",
        "\n",
        "# Evaluation of the model\n",
        "testing_model.evaluation(data_loaders)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZqtxQOacqqC",
        "colab_type": "text"
      },
      "source": [
        "### Understanding the code\n",
        "This code block can be used to plot images from the respective dataset. Use to get an understanding of the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBJH9afVY6Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# understanding the data and plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample = next(iter(train_loader))\n",
        "image, label = sample\n",
        "\n",
        "grid = torchvision.utils.make_grid(image[0:20], nrow=10 )\n",
        "plt.figure(figsize=(14,15))\n",
        "plt.imshow(np.transpose(grid, (1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}